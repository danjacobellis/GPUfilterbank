{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5584726-6066-4e0b-a619-935ea68e7efe",
   "metadata": {},
   "source": [
    "# Notebook to PDF (as a document)\n",
    "\n",
    "`jupyter-nbconvert written_report.ipynb --to pdf -TagRemovePreprocessor.remove_cell_tags='{\"remove_cell\"}' --template template.tplx`\n",
    "\n",
    "# Notebook to slide deck\n",
    "\n",
    "`jupyter-nbconvert presentation.ipynb --to slides --TagRemovePreprocessor.remove_input_tags={\\\"remove-input\\\"} --post serve --ServePostProcessor.port=9997 --ServePostProcessor.ip=\"0.0.0.0\"`\n",
    "\n",
    "http://72.179.3.141:9997/nov8.slides.html\n",
    "\n",
    "To convert to pdf, add ?print-pdf to URL, i.e.\n",
    "\n",
    "http://72.179.3.141:9997/nov8.slides.html?print-pdf\n",
    "\n",
    "Coverage of topics:\n",
    "\n",
    "## Dan\n",
    "\n",
    "part one:\n",
    "* Background\n",
    "* Time-frequency analysis\n",
    "* Time - frequency tilings\n",
    "* Constant-Q \n",
    "* perfect reconstruction\n",
    "* Existing transforms and software\n",
    "  * STFT\n",
    "  * mel-filterbanks using FFT\n",
    "  * Discrete wavelet transforms\n",
    "* common techniques do not have perfect reconstruction\n",
    "  * Either have uniform frequency resolution or perfectly constant-Q\n",
    "    * uniform resolution leads to poor time resolution for high frequencies\n",
    "    * uniform resolution leads to poor frequency resolution for low frequencies\n",
    "    * perfectly constant-Q transforms lead to data structure which is impossible to work with.\n",
    "  * mel filterbanks try to provide a compromise in resolution, but in doing so introduces new problems.\n",
    "    * Undersampled for some frequency bands\n",
    "    * oversampled for others\n",
    "  * FFT based methods require real and imaginary.\n",
    "    * Leads to phase reconstruction problem.\n",
    "    * End up making more work for yourself by having to do griffin-lim or similar algorithm to solve problem which should not have been there in the first place.\n",
    "* Size of data\n",
    "* Compression and storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a73d47-188d-48b1-8f97-67fc778082f3",
   "metadata": {},
   "source": [
    "## Utsha\n",
    "* Haar filter (1min)\n",
    "  * Simplest, dyadic filter\n",
    "  * Perfect reconstruction\n",
    "  * We are using as our building block\n",
    "* Discussion about GPU & Convolution (2min)\n",
    "  * What is Convolution? (Toeplitz, etc)\n",
    "  * Sequential vs Parallel Convolution\n",
    "  * GPU's analysis and bottlenecks\n",
    "* Our algorithm (3min)\n",
    "  * Dyadic Analysis & Sysnthesis Filterbank\n",
    "  * Convolution as a building block\n",
    "  * Decimation & Polyphase filters to utilize convolution\n",
    "  * Cascading unbalanced & balanced binary tree structure\n",
    "* Complexity analysis (1min)\n",
    "* Experiment Results (2min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67440f7a-35ca-4f4d-a736-371a754e1af9",
   "metadata": {},
   "source": [
    "## Dan\n",
    "\n",
    "* Denoising demo\n",
    "\n",
    "* Drawbacks of our method\n",
    "  * not shift invariant\n",
    "    * can be fixed by dual-tree complex wavelet transform\n",
    "    * effectively oversamples by two\n",
    "  * We used Haar filters (two point sum and difference).\n",
    "    * Frequency selectivity may not be as good\n",
    "  * Not fully constant-Q\n",
    "    * makes some analysis much easier, but others might be more difficult\n",
    "    * example: music transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2943c4-f6a5-4bef-9bf9-2f09dce560dc",
   "metadata": {},
   "source": [
    "# GPU Filter Banks for Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8783bec1-3904-4815-ba11-96c0a53b3468",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "In our project, we implement a class of perfect-reconstruction filterbanks for audio analysis. We exploit parallelism across CPU threads for part of our algorithm and use a GPU to solve embarassingly parallel subtasks. We also introduce a novel type of time-frequency tiling which retains the benefits of constant-Q transforms without requiring their cumbersome data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d9eaca-60c1-4051-a7da-0ce825366f24",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "For audio signal processing problems such as compression, denoising, and various types of pattern recognition, deep learning has taken over. For example, the search interest for \"wavelet\" has followed the opposite trajectory as \"convolutional neural network\"\n",
    "\n",
    "![](img/trends1.png)\n",
    "\n",
    "A current trend of audio signal processing research is to apply 2D convolutional neural networks to time-frequency representations of audio. Although great progress was made in the pre-deep learning era on perfect reconstruction filterbanks and wavelet transforms, most of the algorithms and techniques have been abandoned by practitioners of deep learning because no standardized and free implementations were ever widely disseminated. As a result, the standarized set of triangular \"Mel\" filterbanks dating back nearly 50 years appears to have remained the dominant tool, and have even seen a resurgance despite their [impending obsolescence.][1]\n",
    "\n",
    "![](img/trends2.png)\n",
    "\n",
    "The use of these methods is accumulating a considerable debt. Compared to the most recent iterations of constant-Q filterbanks, these methods for time-frequency analysis lack several desirable properties\n",
    "\n",
    "* Parameterization/tunability\n",
    "* Perfect reconstruction\n",
    "* Meaningful/interpretable phase representation\n",
    "* Generalization to multiple channels/phased arrays\n",
    "* Efficient implementation for oversampled representations.\n",
    "\n",
    "[1]:https://asmp-eurasipjournals.springeropen.com/articles/10.1186/s13636-021-00217-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab300cc-3c40-4783-bdd0-e95cbff788b0",
   "metadata": {},
   "source": [
    "# Filter Banks and Wavelet Transforms\n",
    "\n",
    "Filter banks are the oldest method of time-frequency analysis, dating back to the first analog spectrum analyzer built by Hermann von Helmholtz in the 19th century.\n",
    "\n",
    "![](img/helmholtz.png)\n",
    "\n",
    "In 1909, mathematician Alfréd Haar discovered that a list of $2^n$ numbers can be represented by recursively taking the sum and difference of adjacent pairs. This property is now commonly referred to 'alias cancellation'\n",
    "\n",
    "In the 1970s, engineers created the first discrete, invertible filterbanks by expoiting this property. Using what are known as 'conjugate mirror filters'. In the following decade, a massive research effort took place, resulting in a rigorous mathematical understanding of these processes and the development of various \"wavelet transforms.\"\n",
    "\n",
    "Unfortunately, deep learning has begun to displace these techniques in education, leading to considerable confusion and technical debt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27045d-85f7-4c67-a7f4-241b0f4a9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef11f8-69c2-4a54-94f2-c6198d816d9f",
   "metadata": {},
   "source": [
    "# Haar Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8299fc7-9023-465b-b098-b33aeb36f1ab",
   "metadata": {},
   "source": [
    "(Draft) Haar decomposition is one of the simplest wavelet transform that has perfect reconstruction property, thus is a good introduction example. First of all, note that the input is a sequence of integers, because we are dealing digital data after sampling from raw data, such as audio. By performing two convolutions with the input, we get a low-frequency component and a high-frequency component.\n",
    "As we can see, the sum and difference of the high and low frequency components forms a splitted signal of the original signal, which we can merge to retain the original one. This is an example of “critically sampled” dyadic filterbank, which means that the size of data after applying the filter is exactly same as original data. Note that, “dyadic filters” refers “dynamic analysis filters”, the type of filtering that consists of a filtering followed by downsampling. There is an inverse operation, which is synthetic filters. (Which we are dealing by convolution. We will get to this detail later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066cd44-7c62-4fbd-b160-66783cd3f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = round.(Int,10*randn(8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03901d8c-b5ab-4da8-b51d-1a8da0a5ee8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 1, -13, 20, 4, 7, -18, 5]"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417035d7-f0a9-40db-bb3e-3dd61c99989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = conv(x,[1, 1])[2:2:end];\n",
    "d = conv(x,[1,-1])[2:2:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774523ee-69c3-451e-83fd-dcc874586656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [8, 7, 11, -13]\n",
      "d = [-6, 33, 3, 23]"
     ]
    }
   ],
   "source": [
    "println(\"s = \",s); print(\"d = \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88bd14c-6dd3-4df3-a4c1-a799285ebe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = (s-d)/2;\n",
    "y2 = (s+d)/2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3734404-b6b3-4f8d-b586-c3f25a6e7fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, -13, 4, -18]\n",
      "[1, 20, 7, 5]"
     ]
    }
   ],
   "source": [
    "println(Int.(y1)); print(Int.(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c7ca2-ad70-42e3-8216-e0afb6d97476",
   "metadata": {},
   "source": [
    "This is an example of a **critically sampled** dyadic filterbank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997bcccf-5227-4d3f-a237-30c335445670",
   "metadata": {},
   "source": [
    "# Time-frequency tiling\n",
    "\n",
    "\n",
    "\n",
    "Decomposing the lower branch produces octave filters\n",
    "\n",
    "img/dyadic_analysis_filterbank.svg\n",
    "\n",
    "![](img/octave_tiling.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b0511b-5860-4ded-a027-c4f3b94ce225",
   "metadata": {},
   "source": [
    "Decomposing both branches (balanced tree)\n",
    "\n",
    "(uniform grid of rectangles) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fbbc2a-acba-4f47-a500-122d8edae4e8",
   "metadata": {},
   "source": [
    "you can have anything in the middle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a7e9f-4542-4116-a8a4-fc2dcb00659c",
   "metadata": {},
   "source": [
    "(Draft)\n",
    "In the Haar decomposition, we received two signals with half time resolution but twice the frequency resolution signals, by applying the filters. Next, we introduce a more fine-grained time-frequency tiling pattern, as shown in the image.\n",
    "\n",
    "This structure has the benefit of a simple data structure, since each tile is a vector, while providing the exact trade-off between the frequency resolution and the time resolution as we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9966f-c7ae-4d3c-9e3d-3b73135327cf",
   "metadata": {},
   "source": [
    "# DWT Sequential time complexity\n",
    "\n",
    "each level is N log N\n",
    "\n",
    "log N levels\n",
    "\n",
    "between N log N and N (log N)^2\n",
    "\n",
    "regardless of how many levels you go down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a86d1-a862-4295-8ac2-b1621b8d024c",
   "metadata": {},
   "source": [
    "(Draft) In general, we have between $N\\log N$ and $N (\\log N)^2$ time complexity to perform any discrete wavelet transform, because at each level of filtering tree, it takes $N \\log N$ time and there are $\\log N$ levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e9e61-df5f-4471-b39d-c473d63e795b",
   "metadata": {},
   "source": [
    "# parallel fft complexity (and therefore convolution)\n",
    "\n",
    "log N levels\n",
    "\n",
    "each level n/p computation\n",
    "\n",
    "(N/p) log N\n",
    "\n",
    "parallel DWT is\n",
    "\n",
    "(N/p) (log N)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b69e7-1110-40c8-b4d8-190ceecdb911",
   "metadata": {},
   "source": [
    "(Draft) Parallel FFT (Fast Fourier Transform) is widely used in any signal processing application. We can see FFT as a version of filterbank, which breaks the input signal down all the way to full frequency resolution, but with no time resolution. \n",
    "\n",
    "Similar to general DWT, we can see FFT consisting of $\\log N$ levels. Each level has $\\frac{N}{p}$ computation\n",
    ", thus time complexity for parallel FFT is $(\\frac{N}{p})\\log N$. In contrast, parallel DWT takes $(\\frac{N}{p})(\\log N)^2$ time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59360456-080e-4155-83f6-a7f6920a8840",
   "metadata": {},
   "source": [
    "# Input size\n",
    "\n",
    "Speech: few seconds long, fs = 16000, N ~ 10^5 per record.\n",
    "\n",
    "Music: minutes long, two channels, fs = 48000, N ~ 10^7 per record.\n",
    "\n",
    "Passive sonar array: 100s of channels, fs in the kHz, ~ 10^10 per hour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4219786d-64e9-4278-bfdb-b6a43bd7c394",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "\n",
    "Speech and music are nearly always compressed. Typical compression ratio is 10:1\n",
    "\n",
    "Phased array data often minimally compressed and stored on cheap magnetic tape.\n",
    "\n",
    "Often helpful to combine PRAM and GPU computation models.\n",
    "\n",
    "Multiple CPUs can increase the rate at which data is decoded and communicated to the GPU(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76583610-40fd-49da-87ff-62bdd32589d6",
   "metadata": {},
   "source": [
    "# Generalization to other filters\n",
    "\n",
    "You need alias cancellation\n",
    "\n",
    "https://en.wikipedia.org/wiki/Quadrature_mirror_filter\n",
    "\n",
    "As long as you satisfy this condition, you can use better filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c4387-b2eb-4306-ad0f-e9e640a3bf65",
   "metadata": {},
   "source": [
    "(Draft) The framework to process the input signal by the analysis filterbank and then reconstruct to get it back is generalizable. We can apply any operation on the in-between layer (i.e. the processed small data blocks) and retain the perfect reconstruction property, as long as the operation has mirror-conjugate property. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44381c59-b801-4d9d-bdbe-28b7d7a22d6e",
   "metadata": {},
   "source": [
    "# Discrete wavelet transform\n",
    "\n",
    "Generalizes this idea "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295286b8-2e48-492d-8c95-d476a68f849a",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Generalize these types of transformations to\n",
    "\n",
    "* Filters with greater frequency selectivity\n",
    "* Oversampled filters\n",
    "* Undersampled filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cb898f-a115-4d05-8d6e-6a356c451b43",
   "metadata": {},
   "source": [
    "# GPU convolution\n",
    "\n",
    "what is CUDA doing?\n",
    "\n",
    "https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html\n",
    "\n",
    "If you repeat your data and construct \n",
    "\n",
    "https://en.wikipedia.org/wiki/Toeplitz_matrix\n",
    "\n",
    "Then convolution is equivalent to matrix multiply\n",
    "\n",
    "Not actually doing matrix multiplication, but create a mapping from \"virtual matrix\" to corresponding array location\n",
    "\n",
    "(fold in some of the theory from lecture on mat mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d89a96a-1800-4047-818b-206ebe456b24",
   "metadata": {},
   "source": [
    "(Draft) We utilized existing implementation of CuDNN convolution, as it is optimized for GPU as shipped. The convolution on digital signal can be expressed as a multiplication of Toepliz matrix and the convolution kernel - whose rows consists of a shifted element of the original signal (i.e. sequence of numbers).\n",
    "Note that Toepliz matrix multiplication is much efficient than regular matrix multiplication, because in implementation we do not need to store data in a matrix. Instead, it can be operated with indices and compute convolution, by creating a mapping from “virtual matrix” to the corresponding array location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1adb456-b86c-4af6-b6a3-e95fc730ec21",
   "metadata": {},
   "source": [
    "convolution is identical to mat vec multiply $Ax$ where $A$ is $N \\times (N-M+\\text{pad})$ toeplitz and $x$ is $(N-M+\\text{pad})\\times 1$\n",
    "\n",
    "$\\text{pad} \\in [0,M]$ is the amount of zero padding\n",
    "\n",
    "$N$ is signal length\n",
    "\n",
    "$M$ is filter length\n",
    "\n",
    "Sequential algorithm for convolution:\n",
    "\n",
    "$(N-M+\\text{pad})$ dot products.  Each dot product takes $M^2$ multiplies  and $M-1$ additions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192d02e-3874-4759-b080-d3b5df8e87f2",
   "metadata": {},
   "source": [
    "$ y = x \\ast h = \n",
    "\\begin{bmatrix}\n",
    "    x_1 & 0 & \\cdots & 0 & 0 \\\\\n",
    "    x_2 & x_1 &      & \\vdots & \\vdots \\\\\n",
    "    x_3 & x_2 & \\cdots & 0 & 0 \\\\\n",
    "    \\vdots & x_3 & \\cdots & x_1 & 0 \\\\\n",
    "    x_{n-1} & \\vdots & \\ddots & x_2 & x_1 \\\\\n",
    "    x_n & x_{n-1} &      & \\vdots & x_2 \\\\\n",
    "    0 & x_n & \\ddots & x_{n-2} & \\vdots \\\\\n",
    "    0 & 0 & \\cdots & x_{n-1} & x_{n-2} \\\\\n",
    "    \\vdots & \\vdots &        & x_n & x_{n-1} \\\\\n",
    "    0 & 0 & 0 & \\cdots & x_n\n",
    "\\end{bmatrix}\n",
    "$\n",
    "$\\begin{bmatrix}\n",
    "    0 \\\\\n",
    "    0 \\\\\n",
    "    \\vdots\\\\\n",
    "    h_1 \\\\\n",
    "    h_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    h_m \\\\\n",
    "    0 \\\\\n",
    "    \\vdots \\\\\n",
    "    0 \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014752b7-e426-486e-be2e-455cda3a74bc",
   "metadata": {},
   "source": [
    "## parallel convolution\n",
    "\n",
    "Option 1: number of available processors is approximately N:\n",
    "\n",
    "Use $p=(N-M+\\text{pad})$ processors, Each processor does the dot product sequentially using $M^2$ multiplies and $M-1$ additions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee178f1-d144-4e67-b903-31b8ce5de4fe",
   "metadata": {},
   "source": [
    "Second option: number of available processors is $\\geq NM$\n",
    "\n",
    "use $NM$ processors to perform all $N$ Hadamard products in parallel.\n",
    "\n",
    "Use parallel reduce to compute the sum in $log_2(M)$ steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22a018-07c0-4b30-84ec-2fe2449c2aab",
   "metadata": {},
   "source": [
    "### Question: how many $p$ would we need for audio signals?\n",
    "\n",
    "Speech: few seconds long, fs = 16000, N ~ 10^5 per record.\n",
    "\n",
    "Music: minutes long, two channels, fs = 48000, N ~ 10^7 per record.\n",
    "\n",
    "Passive sonar array: 100s of channels, fs in the kHz, ~ 10^10 per hour.\n",
    "\n",
    "### Ideally, we would have 10^10 processors.\n",
    "\n",
    "In practice N is limited by the ability of CPU/ data storage to stream data onto the GPU.\n",
    "\n",
    "GPU clock rate is typically about 1 Ghz. There is $\\approx 1 \\text{ns}$ between clock cycles on GPU. N is chosen based on how much data can be loaded into memory in that period of time.\n",
    "\n",
    "For small M, convolution is effectively $O(1)$ on GPU, but is limited by memory transfer rate.\n",
    "\n",
    "Deep learning practitioners have highly optimized this problem (convolution between large N and small M). We want to build our algorithm on top of their software and highly optimized data pipeline.\n",
    "\n",
    "Exactly the type of thing that GPUs are built for.\n",
    "\n",
    "Use gpus which act like $p = O(10^3)$ processors. Break up data so that $NM$ words of data can be stored on the gpu.\n",
    "\n",
    "often bottlenecked by ability of CPU to decode compressed data.\n",
    "\n",
    "Really just limited by ability of CPU to transfer memory back and forth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45742bda-0e10-4cd0-8c26-05fde882132a",
   "metadata": {},
   "source": [
    "# Fundamental building block of our algorithm:\n",
    "\n",
    "Highly optimized CuDNN convolution routine which is suited to large N and small M.\n",
    "\n",
    "If M is small enough, limited by memory transfer.\n",
    "\n",
    "If M is large, limited by GPU clock rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775df69-4fbf-4e69-aeb2-95174317d8cc",
   "metadata": {},
   "source": [
    "If we go all the way from time domain to frequency domain, binary tree would have depth of $log N$. In practice, we stop about halfway through.\n",
    "\n",
    "This results in roughly equal time and frequency resolution which is what we want for useful signal processing tasks (denoising, compression, statistical learning, etc).\n",
    "\n",
    "Summary: time complexity of our algorithm is $O(log N)$, but in practice is limited by transfer rate since $M$ is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c32c51-ebb6-44f9-9e3e-1ce06c8534f4",
   "metadata": {},
   "source": [
    "## parallel dot product\n",
    "\n",
    "product part can also be computed in parallel trivially\n",
    "\n",
    "sum is just parallel reduce.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6789233-25a7-42df-8797-6cb4bc59e3cc",
   "metadata": {},
   "source": [
    "# Decimation filterbank\n",
    "\n",
    "filter then downsample\n",
    "\n",
    "!= dilation + stride (but close)\n",
    "\n",
    "show toeplitz matrix multiplication with upsampling/downsampling\n",
    "\n",
    "# Polyphase filterbank\n",
    "\n",
    "http://users.ece.utexas.edu/~bevans/courses/realtime/lectures/13_Digital_PAM/lecture13.ppt\n",
    "\n",
    "upsample then filter\n",
    " \n",
    "?= transposed convolution with dilation and stride\n",
    "\n",
    "Another oppurtunity to add CPU parallelism\n",
    "\n",
    "show mathematically that it's equivalent to splitting filter into L pieces where L is the upsampling factor, and applying filters in parallel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242cb31-edeb-4b77-9e13-e0b720ccd5a0",
   "metadata": {},
   "source": [
    "# Oversampled filterbanks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8861df-d80c-4ec0-9819-65fbfcbabef3",
   "metadata": {},
   "source": [
    "(Draft) Oversampled filterbanks refers to the type of filterbank that results in larger sized output data compared to the input. For example, Fourier Transform is an oversampled filtering with factor 2, as it yields a signal in frequency domain and the phase domain. \n",
    "\n",
    "Because of this nature, oversampled filterbank can get better CPU parallelism by having multiple data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43dd3d-b7fe-49af-870a-76bd6a8f1e27",
   "metadata": {},
   "source": [
    "# Undersampled filterbanks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96bceaf-d44a-4138-a58f-ae6657e6a3e4",
   "metadata": {},
   "source": [
    "(Draft) In contrast to oversampled filterbanks, undersampled filterbank results in smaller sized output data compared to the input data. An example is convolving input signal with a small kernal without paddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b4b22-6327-4274-adc3-1cb1c51411cc",
   "metadata": {},
   "source": [
    "# Analysis filterbank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad44fa-ce9b-4df5-adc7-1f42fd8e89ad",
   "metadata": {},
   "source": [
    "# Synthesis filterbank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df984e-c523-4ba7-a769-86dd62043ecf",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "* denoising\n",
    "* compression\n",
    "* source separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be81dad-7d11-46aa-8107-4ffb4b76fa96",
   "metadata": {},
   "source": [
    "# Octave Filters + Balanced Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2e05f-7cb3-4706-9a67-c63d0a84b635",
   "metadata": {},
   "source": [
    "In our filter, we repeatedly apply analysis filters to break down the input signal and synthesis filters to reconstruct from broken down (and possibly processed) pieces. As shown in the earlier image, this has an unbalanced tree structure where we apply analysis filters to the higher frequency-band output at each level, but leave the lower frequency-band output. This is a natural structure, as human ear processes sound signals in a similar way. \n",
    "\n",
    "In our algorithm, we break down the signal into 11 octaves, as 11 is mostly sufficient to cover human’s hearing capability. As a result, we get 11 vectors, where higher frequency blocks have better resolution.  Note that, we can apply any operation on these vectors and still retain the reconstruction property, as long as the operation has the mirror-conjugate property.\n",
    "\n",
    "Following the octave-spaced analysis filter, we apply dyadic filters in a balanced-tree fashion (i.e. apply filters to both high and low frequency outputs), to obtain some fixed frequency-resolution blocks out of the imbalanced length blocks from the previous step. \n",
    "\n",
    "Now, we have obtained 11 blocks of signals, decomposed from the orignal signal, where each block has the exact same frequency resolutions. We can see this as a feature representatino of the original data, where the features size is exactly same as original (i.e. critially sampled). \n",
    "\n",
    "Later, we will demonstrate the ease of use with this decomposition. We can perform various useful operations such as denoising and comporession with very simple code, and it is highly efficient due to massive parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16f46d-5469-4639-8764-4fff3bb4aee4",
   "metadata": {},
   "source": [
    "# Demo our program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7b70b-b52b-498f-b181-bfe728099a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c57ad9e9-04af-4de8-ac97-a3906d0cdcc9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0-beta3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
