{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36efef1-515b-4518-bd09-cdff89f1c978",
   "metadata": {},
   "source": [
    "# GPU Filter Banks for Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f2402-79cf-4f5b-88e0-38124b41ae1c",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "In our project, we implement a class of perfect-reconstruction filterbanks for audio analysis. We exploit parallelism across CPU threads for part of our algorithm and use a GPU to solve embarassingly parallel subtasks. We also introduce a novel type of time-frequency tiling which retains the benefits of constant-Q transforms without requiring their cumbersome data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e37a0-d4f9-403f-b248-bf40a2e1ae03",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "For audio signal processing problems such as compression, denoising, and various types of pattern recognition, deep learning has taken over. For example, the search interest for \"wavelet\" has followed the opposite trajectory as \"convolutional neural network\"\n",
    "\n",
    "![](img/trends1.png)\n",
    "\n",
    "A current trend of audio signal processing research is to apply 2D convolutional neural networks to time-frequency representations of audio. Although great progress was made in the pre-deep learning era on perfect reconstruction filterbanks and wavelet transforms, most of the algorithms and techniques have been abandoned by practitioners of deep learning because no standardized and free implementations were ever widely disseminated. As a result, the standarized set of triangular \"Mel\" filterbanks dating back nearly 50 years appears to have remained the dominant tool, and have even seen a resurgance despite their [impending obsolescence.][1]\n",
    "\n",
    "![](img/trends2.png)\n",
    "\n",
    "The use of these methods is accumulating a considerable debt. Compared to the most recent iterations of constant-Q filterbanks, these methods for time-frequency analysis lack several desirable properties\n",
    "\n",
    "* Parameterization/tunability\n",
    "* Perfect reconstruction\n",
    "* Meaningful/interpretable phase representation\n",
    "* Generalization to multiple channels/phased arrays\n",
    "* Efficient implementation for oversampled representations.\n",
    "\n",
    "[1]:https://asmp-eurasipjournals.springeropen.com/articles/10.1186/s13636-021-00217-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e44b6-ee18-4439-af9a-f06ad6b8cc55",
   "metadata": {},
   "source": [
    "# Filter Banks and Wavelet Transforms\n",
    "\n",
    "Filter banks are the oldest method of time-frequency analysis, dating back to the first analog spectrum analyzer built by Hermann von Helmholtz in the 19th century.\n",
    "\n",
    "![](img/helmholtz.png)\n",
    "\n",
    "In 1909, mathematician Alfréd Haar discovered that a list of $2^n$ numbers can be represented by recursively taking the sum and difference of adjacent pairs. This property is now commonly referred to 'alias cancellation'\n",
    "\n",
    "In the 1970s, engineers created the first discrete, invertible filterbanks by expoiting this property. Using what are known as 'conjugate mirror filters'. In the following decade, a massive research effort took place, resulting in a rigorous mathematical understanding of these processes and the development of various \"wavelet transforms.\"\n",
    "\n",
    "Unfortunately, deep learning has begun to displace these techniques in education, leading to considerable confusion and technical debt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba776c-de20-4883-b8bd-89faaeedce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227ab9b-c01d-4ef6-ad63-d0a1cfa1e666",
   "metadata": {},
   "source": [
    "# Haar Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec4e93-a5ed-4c22-846d-f7dee295943a",
   "metadata": {},
   "source": [
    "(Draft) Haar decomposition is one of the simplest wavelet transform that has perfect reconstruction property, thus is a good introduction example. First of all, note that the input is a sequence of integers, because we are dealing digital data after sampling from raw data, such as audio. By performing two convolutions with the input, we get a low-frequency component and a high-frequency component.\n",
    "As we can see, the sum and difference of the high and low frequency components forms a splitted signal of the original signal, which we can merge to retain the original one. This is an example of “critically sampled” dyadic filterbank, which means that the size of data after applying the filter is exactly same as original data. Note that, “dyadic filters” refers “dynamic analysis filters”, the type of filtering that consists of a filtering followed by downsampling. There is an inverse operation, which is synthetic filters. (Which we are dealing by convolution. We will get to this detail later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48fe8a-f26c-45a5-9d8e-1f939b4730c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = round.(Int,10*randn(8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e9592-aeba-43be-8fa9-7f50381d6939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 1, -13, 20, 4, 7, -18, 5]"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b102f-c3c4-4f3a-9675-bdfcec5937db",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = conv(x,[1, 1])[2:2:end];\n",
    "d = conv(x,[1,-1])[2:2:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84dbf4-e01d-4a10-aee9-4b248c8aef94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [8, 7, 11, -13]\n",
      "d = [-6, 33, 3, 23]"
     ]
    }
   ],
   "source": [
    "println(\"s = \",s); print(\"d = \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ada2d3-4336-45ff-8b61-d20ac52dd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = (s-d)/2;\n",
    "y2 = (s+d)/2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c015b-09e9-4de1-b617-912ba504fd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, -13, 4, -18]\n",
      "[1, 20, 7, 5]"
     ]
    }
   ],
   "source": [
    "println(Int.(y1)); print(Int.(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c7bc8-2468-41d8-9420-b68b16def61c",
   "metadata": {},
   "source": [
    "This is an example of a **critically sampled** dyadic filterbank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6654c-2c77-4f75-b533-8051e6f4ee83",
   "metadata": {},
   "source": [
    "# Time-frequency tiling\n",
    "\n",
    "\n",
    "\n",
    "Decomposing the lower branch produces octave filters\n",
    "\n",
    "img/dyadic_analysis_filterbank.svg\n",
    "\n",
    "![](img/octave_tiling.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97154e-f404-45b2-9b0a-42708588e5f0",
   "metadata": {},
   "source": [
    "Decomposing both branches (balanced tree)\n",
    "\n",
    "(uniform grid of rectangles) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc8b57-144d-476c-bb24-2ff79f6b5610",
   "metadata": {},
   "source": [
    "you can have anything in the middle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be980319-1589-4c71-b7bc-fe0b54360000",
   "metadata": {},
   "source": [
    "(Draft)\n",
    "In the Haar decomposition, we received two signals with half time resolution but twice the frequency resolution signals, by applying the filters. Next, we introduce a more fine-grained time-frequency tiling pattern, as shown in the image.\n",
    "\n",
    "This structure has the benefit of a simple data structure, since each tile is a vector, while providing the exact trade-off between the frequency resolution and the time resolution as we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1dda9c-282b-4f4e-97dd-b49be8fcf59a",
   "metadata": {},
   "source": [
    "# DWT Sequential time complexity\n",
    "\n",
    "each level is N log N\n",
    "\n",
    "log N levels\n",
    "\n",
    "between N log N and N (log N)^2\n",
    "\n",
    "regardless of how many levels you go down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfce19e-d344-4f01-b5a3-4877855cf061",
   "metadata": {},
   "source": [
    "(Draft) In general, we have between $N\\log N$ and $N (\\log N)^2$ time complexity to perform any discrete wavelet transform, because at each level of filtering tree, it takes $N \\log N$ time and there are $\\log N$ levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8558a4-8120-478b-bda6-b6c3a035cbaf",
   "metadata": {},
   "source": [
    "# parallel fft complexity (and therefore convolution)\n",
    "\n",
    "log N levels\n",
    "\n",
    "each level n/p computation\n",
    "\n",
    "(N/p) log N\n",
    "\n",
    "parallel DWT is\n",
    "\n",
    "(N/p) (log N)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc17114-645f-4a1d-a1b0-9ec1283009fb",
   "metadata": {},
   "source": [
    "(Draft) Parallel FFT (Fast Fourier Transform) is widely used in any signal processing application. We can see FFT as a version of filterbank, which breaks the input signal down all the way to full frequency resolution, but with no time resolution. \n",
    "\n",
    "Similar to general DWT, we can see FFT consisting of $\\log N$ levels. Each level has $\\frac{N}{p}$ computation\n",
    ", thus time complexity for parallel FFT is $(\\frac{N}{p})\\log N$. In contrast, parallel DWT takes $(\\frac{N}{p})(\\log N)^2$ time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89832b38-3942-44e3-9745-9fc742a0bc79",
   "metadata": {},
   "source": [
    "# Input size\n",
    "\n",
    "Speech: few seconds long, fs = 16000, N ~ 10^5 per record.\n",
    "\n",
    "Music: minutes long, two channels, fs = 48000, N ~ 10^7 per record.\n",
    "\n",
    "Passive sonar array: 100s of channels, fs in the kHz, ~ 10^10 per hour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38dadc-34c8-4c99-b22b-cc420ef7c0f2",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "\n",
    "Speech and music are nearly always compressed. Typical compression ratio is 10:1\n",
    "\n",
    "Phased array data often minimally compressed and stored on cheap magnetic tape.\n",
    "\n",
    "Often helpful to combine PRAM and GPU computation models.\n",
    "\n",
    "Multiple CPUs can increase the rate at which data is decoded and communicated to the GPU(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942f41e-5988-462b-8517-ff794c81e0ef",
   "metadata": {},
   "source": [
    "# Generalization to other filters\n",
    "\n",
    "You need alias cancellation\n",
    "\n",
    "https://en.wikipedia.org/wiki/Quadrature_mirror_filter\n",
    "\n",
    "As long as you satisfy this condition, you can use better filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842187cb-39c7-44ba-8f5b-3d1639a34958",
   "metadata": {},
   "source": [
    "(Draft) The framework to process the input signal by the analysis filterbank and then reconstruct to get it back is generalizable. We can apply any operation on the in-between layer (i.e. the processed small data blocks) and retain the perfect reconstruction property, as long as the operation has mirror-conjugate property. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c40a8-ace6-48af-bd8b-654174da587c",
   "metadata": {},
   "source": [
    "# Discrete wavelet transform\n",
    "\n",
    "Generalizes this idea "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a5b1b-42dd-44be-aa86-a60baf35c102",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Generalize these types of transformations to\n",
    "\n",
    "* Filters with greater frequency selectivity\n",
    "* Oversampled filters\n",
    "* Undersampled filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc921eca-493e-4a73-9c2e-036ff86c2a64",
   "metadata": {},
   "source": [
    "# GPU convolution\n",
    "\n",
    "what is CUDA doing?\n",
    "\n",
    "https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html\n",
    "\n",
    "If you repeat your data and construct \n",
    "\n",
    "https://en.wikipedia.org/wiki/Toeplitz_matrix\n",
    "\n",
    "Then convolution is equivalent to matrix multiply\n",
    "\n",
    "Not actually doing matrix multiplication, but create a mapping from \"virtual matrix\" to corresponding array location\n",
    "\n",
    "(fold in some of the theory from lecture on mat mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990aa882-ecce-44ff-a500-517425c754b7",
   "metadata": {},
   "source": [
    "(Draft) We utilized existing implementation of CuDNN convolution, as it is optimized for GPU as shipped. The convolution on digital signal can be expressed as a multiplication of Toepliz matrix and the convolution kernel - whose rows consists of a shifted element of the original signal (i.e. sequence of numbers).\n",
    "Note that Toepliz matrix multiplication is much efficient than regular matrix multiplication, because in implementation we do not need to store data in a matrix. Instead, it can be operated with indices and compute convolution, by creating a mapping from “virtual matrix” to the corresponding array location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a750b-dd97-4351-bd9a-f463bcb68e24",
   "metadata": {},
   "source": [
    "# Decimation filterbank\n",
    "\n",
    "filter then downsample\n",
    "\n",
    "!= dilation + stride (but close)\n",
    "\n",
    "show toeplitz matrix multiplication with upsampling/downsampling\n",
    "\n",
    "# Polyphase filterbank\n",
    "\n",
    "http://users.ece.utexas.edu/~bevans/courses/realtime/lectures/13_Digital_PAM/lecture13.ppt\n",
    "\n",
    "upsample then filter\n",
    " \n",
    "?= transposed convolution with dilation and stride\n",
    "\n",
    "Another oppurtunity to add CPU parallelism\n",
    "\n",
    "show mathematically that it's equivalent to splitting filter into L pieces where L is the upsampling factor, and applying filters in parallel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a35ca6-8e59-47fe-b916-6060f50f40fc",
   "metadata": {},
   "source": [
    "# Oversampled filterbanks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0323b02b-a111-4a93-9f07-fb986d5fb2b9",
   "metadata": {},
   "source": [
    "(Draft) Oversampled filterbanks refers to the type of filterbank that results in larger sized output data compared to the input. For example, Fourier Transform is an oversampled filtering with factor 2, as it yields a signal in frequency domain and the phase domain. \n",
    "\n",
    "Because of this nature, oversampled filterbank can get better CPU parallelism by having multiple data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e7340-24fc-4005-a699-09c0055389c4",
   "metadata": {},
   "source": [
    "# Undersampled filterbanks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751f030-c5dd-4ed7-bf66-ba671a2c1c94",
   "metadata": {},
   "source": [
    "(Draft) In contrast to oversampled filterbanks, undersampled filterbank results in smaller sized output data compared to the input data. An example is convolving input signal with a small kernal without paddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6e7dd-f8a2-4946-b36a-1b4356764e29",
   "metadata": {},
   "source": [
    "# Analysis filterbank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0575fc0-345f-4d65-b3b7-0a5f3266d57f",
   "metadata": {},
   "source": [
    "# Synthesis filterbank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bea6fc-ed8e-4359-a3ef-bd8ccddae7b6",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "* denoising\n",
    "* compression\n",
    "* source separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296e1f7-ecfa-4036-8226-7c19e625b983",
   "metadata": {},
   "source": [
    "# Octave Filters + Balanced Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f1a373-6a37-41f1-bed1-05e0ec192787",
   "metadata": {},
   "source": [
    "In our filter, we repeatedly apply analysis filters to break down the input signal and synthesis filters to reconstruct from broken down (and possibly processed) pieces. As shown in the earlier image, this has an unbalanced tree structure where we apply analysis filters to the higher frequency-band output at each level, but leave the lower frequency-band output. This is a natural structure, as human ear processes sound signals in a similar way. \n",
    "\n",
    "In our algorithm, we break down the signal into 11 octaves, as 11 is mostly sufficient to cover human’s hearing capability. As a result, we get 11 vectors, where higher frequency blocks have better resolution.  Note that, we can apply any operation on these vectors and still retain the reconstruction property, as long as the operation has the mirror-conjugate property.\n",
    "\n",
    "Following the octave-spaced analysis filter, we apply dyadic filters in a balanced-tree fashion (i.e. apply filters to both high and low frequency outputs), to obtain some fixed frequency-resolution blocks out of the imbalanced length blocks from the previous step. \n",
    "\n",
    "Now, we have obtained 11 blocks of signals, decomposed from the orignal signal, where each block has the exact same frequency resolutions. We can see this as a feature representatino of the original data, where the features size is exactly same as original (i.e. critially sampled). \n",
    "\n",
    "Later, we will demonstrate the ease of use with this decomposition. We can perform various useful operations such as denoising and comporession with very simple code, and it is highly efficient due to massive parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f8aae-2c5f-4aa1-ba21-22815d49f20a",
   "metadata": {},
   "source": [
    "# Demo our program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0-beta3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
